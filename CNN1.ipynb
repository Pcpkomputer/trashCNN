{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Memuat Feature dan Label dari penyimpanan Pickle\n",
    "\n",
    "import pickle\n",
    "\n",
    "X_train=pickle.load(open(\"D:/~fucking6/~Fucking Skripshit/github/X_train.p\",\"rb\"))\n",
    "y_train=pickle.load(open(\"D:/~fucking6/~Fucking Skripshit/github/y_train.p\",\"rb\"))\n",
    "\n",
    "X_test=pickle.load(open(\"D:/~fucking6/~Fucking Skripshit/github/X_test.p\",\"rb\"))\n",
    "y_test=pickle.load(open(\"D:/~fucking6/~Fucking Skripshit/github/y_test.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22564 samples, validate on 2513 samples\n",
      "Epoch 1/5\n",
      "22564/22564 [==============================] - 19s 843us/sample - loss: 0.6012 - accuracy: 0.6787 - val_loss: 0.5273 - val_accuracy: 0.7457\n",
      "Epoch 2/5\n",
      "22564/22564 [==============================] - 18s 811us/sample - loss: 0.5493 - accuracy: 0.7240 - val_loss: 0.5156 - val_accuracy: 0.7692\n",
      "Epoch 3/5\n",
      "22564/22564 [==============================] - 18s 790us/sample - loss: 0.5214 - accuracy: 0.7439 - val_loss: 0.5064 - val_accuracy: 0.7624\n",
      "Epoch 4/5\n",
      "22564/22564 [==============================] - 18s 801us/sample - loss: 0.4980 - accuracy: 0.7595 - val_loss: 0.5654 - val_accuracy: 0.7187\n",
      "Epoch 5/5\n",
      "22564/22564 [==============================] - 18s 795us/sample - loss: 0.4790 - accuracy: 0.7723 - val_loss: 0.5090 - val_accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d69a9dee88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Arsitektur CNN 1\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "import datetime\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\fits\\\\CNN1_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),histogram_freq=1, profile_batch = 100000000)\n",
    "\n",
    "\n",
    "# Mendefinisikan Jenis Model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer Convolutional\n",
    "model.add(Conv2D(32,(3,3), input_shape=(32,32,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Layer MaxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Proses Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=5,validation_data=(X_test,y_test), callbacks=[tensorboard])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
